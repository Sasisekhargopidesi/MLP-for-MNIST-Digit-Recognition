# MLP-for-MNIST-Digit-Recognition
Developed and trained Multi-Layer Perceptron (MLP) models with 1-4 hidden layers to classify handwritten digits from the MNIST dataset. Implemented forward and backward propagation with NumPy, used dropout for regularization, and achieved ~95% accuracy. Evaluated performance using confusion matrix and metrics.
